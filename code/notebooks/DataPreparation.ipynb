{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import urllib.request as ur\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "data_folder = '../data/'\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(data_folder):\n",
    "    os.makedirs(data_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Swissmetro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(data_folder + 'GEV_SM'):\n",
    "    os.makedirs(data_folder + 'GEV_SM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../data/GEV_SM/swissmetro.dat', <http.client.HTTPMessage at 0x7f5670fb1f28>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ur.urlretrieve(\"http://transp-or.epfl.ch/data/swissmetro.dat\", \n",
    "               data_folder + \"GEV_SM/swissmetro.dat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LondonTravel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(data_folder + 'LondonTravel'):\n",
    "    os.makedirs(data_folder + 'LondonTravel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contact Tim Hillel (tim.hillel@epfl.ch) to get access to his dataset. Place the files in the folder `data/LondonTravel`. The files should be named `12_13.csv` and `14.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_folder + 'LondonTravel/12_13.csv')\n",
    "df_12 = df[df['survey_year'] == 12]\n",
    "df_14 = pd.read_csv(data_folder + 'LondonTravel/14.csv')\n",
    "df_tot = df.append(df_14)\n",
    "\n",
    "df_tot.to_csv(data_folder + 'LondonTravel/12_13_14.csv', index=False)\n",
    "df_12.to_csv(data_folder + 'LondonTravel/12.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MTMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(data_folder + 'MTMC'):\n",
    "    os.makedirs(data_folder + 'MTMC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please contact Christophe Siegenthaler (mobilita2015@bfs.admin.ch) for the data. Then, you can follow the instructions on Antonin Danalet's Github repository to prepare the data. (https://github.com/antonindanalet/mobility-resources-in-switzerland-in-2015) His model is in Bison, while the model in this repository is in python using Pandas Biogeme, the latest version of Biogeme."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(data_folder + 'Optima'):\n",
    "    os.makedirs(data_folder + 'Optima')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../data/Optima/optima.dat', <http.client.HTTPMessage at 0x7f5670f4ea20>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ur.urlretrieve(\"http://transp-or.epfl.ch/data/optima.dat\", \n",
    "               data_folder + \"Optima/optima.dat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Airline Itinerary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(data_folder + 'AirlineItinerary'):\n",
    "    os.makedirs(data_folder + 'AirlineItinerary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../data/AirlineItinerary/airline.dat',\n",
       " <http.client.HTTPMessage at 0x7f5670f24cc0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ur.urlretrieve(\"http://transp-or.epfl.ch/data/airline.dat\", \n",
    "               data_folder + \"AirlineItinerary/airline.dat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mode Choice in Netherlands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(data_folder + 'Netherlands'):\n",
    "    os.makedirs(data_folder + 'Netherlands')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../data/Netherlands/netherlands.dat',\n",
       " <http.client.HTTPMessage at 0x7f5670f776a0>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ur.urlretrieve(\"http://transp-or.epfl.ch/data/netherlands.dat\", \n",
    "               data_folder + \"Netherlands/netherlands.dat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parking Choice in Spain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(data_folder + 'Parking'):\n",
    "    os.makedirs(data_folder + 'Parking')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../data/Parking/parking.dat', <http.client.HTTPMessage at 0x7f5670f775f8>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ur.urlretrieve(\"http://transp-or.epfl.ch/data/parking.dat\", \n",
    "               data_folder + \"Parking/parking.dat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Telephone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(data_folder + 'Telephone'):\n",
    "    os.makedirs(data_folder + 'Telephone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../data/Telephone/telephone.dat',\n",
       " <http.client.HTTPMessage at 0x7f5670f77a20>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ur.urlretrieve(\"http://transp-or.epfl.ch/data/telephone.dat\", \n",
    "               data_folder + \"Telephone/telephone.dat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(data_folder + 'Iris'):\n",
    "    os.makedirs(data_folder + 'Iris')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../data/Iris/iris.data', <http.client.HTTPMessage at 0x7f5670f244e0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ur.urlretrieve(\"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\",\n",
    "               data_folder + \"Iris/iris.data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bike Sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(data_folder + 'BikeSharing'):\n",
    "    os.makedirs(data_folder + 'BikeSharing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../data/BikeSharing/Bike-Sharing-Dataset.zip',\n",
       " <http.client.HTTPMessage at 0x7f5670f60278>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ur.urlretrieve(\"https://archive.ics.uci.edu/ml/machine-learning-databases/00275/Bike-Sharing-Dataset.zip\",\n",
    "               data_folder + \"BikeSharing/Bike-Sharing-Dataset.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_ref = zipfile.ZipFile(data_folder + \"BikeSharing/Bike-Sharing-Dataset.zip\", 'r')\n",
    "zip_ref.extractall(data_folder + \"BikeSharing\")\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_folder + \"BikeSharing/hour.csv\")\n",
    "dec = ['2012-12' in a for a in df['dteday']]\n",
    "\n",
    "idx = np.array(range(len(dec)))\n",
    "\n",
    "test = df.iloc[idx[dec]]\n",
    "test.index = range(len(test))\n",
    "test = test.drop('instant', 1)\n",
    "test = test.drop('dteday', 1)\n",
    "test = test.drop('casual', 1)\n",
    "test = test.drop('registered', 1)\n",
    "y = test['cnt']\n",
    "test = test.drop('cnt', 1)\n",
    "test['class'] = np.array(y>80, dtype=int)\n",
    "\n",
    "train = df.iloc[idx[np.invert(dec)]]\n",
    "train.index = range(len(train))\n",
    "train = train.drop('instant', 1)\n",
    "train = train.drop('dteday', 1)\n",
    "train = train.drop('casual', 1)\n",
    "train = train.drop('registered', 1)\n",
    "y = train['cnt']\n",
    "train = train.drop('cnt', 1)\n",
    "train['class'] = np.array(y>80, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(data_folder + \"BikeSharing/train_bike_sharing.csv\", index=False)\n",
    "test.to_csv(data_folder + \"BikeSharing/test_bike_sharing.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-29-f964e9767977>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/gael/Applications/anaconda/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/gael/Applications/anaconda/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From /home/gael/Applications/anaconda/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From /home/gael/Applications/anaconda/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/gael/Applications/anaconda/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=False)\n",
    "\n",
    "X_train = np.vstack([img.reshape(-1,) for img in mnist.train.images])\n",
    "y_train = mnist.train.labels\n",
    "\n",
    "X_test = np.vstack([img.reshape(-1,) for img in mnist.test.images])\n",
    "y_test = mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(data_folder + 'MNIST'):\n",
    "    os.makedirs(data_folder + 'MNIST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(data_folder + 'MNIST/train.dat', X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(data_folder + 'MNIST/test.dat', X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Higgs boson "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(data_folder + 'Higgs'):\n",
    "    os.makedirs(data_folder + 'Higgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../data/Higgs/atlas-higgs-challenge-2014-v2.csv.gz',\n",
       " <http.client.HTTPMessage at 0x7fcc06b170f0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ur.urlretrieve(\"http://opendata.cern.ch/record/328/files/atlas-higgs-challenge-2014-v2.csv.gz\", \n",
    "               data_folder + \"Higgs/atlas-higgs-challenge-2014-v2.csv.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open(data_folder + \"Higgs/atlas-higgs-challenge-2014-v2.csv.gz\") as f:\n",
    "\n",
    "    data = pd.read_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(data_folder + \"Higgs/higgs.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
